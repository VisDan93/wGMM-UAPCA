{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0f9aef",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# wGMM–UAPCA Evaluation Demonstration\n",
    "\n",
    "This notebook presents the **quantitative evaluation** of the wGMM–UAPCA method, as described by Klötzl et al. in [*Uncertainty-Aware PCA for Arbitrarily Distributed Data Modeled by Gaussian Mixture Models*](https://arxiv.org/abs/2508.13990).\n",
    "\n",
    "We focus on **comparing the quality of 2D projections** generated by wGMM–UAPCA against baseline methods such as standard PCA and UAPCA. The evaluation employs the following metrics:\n",
    "\n",
    "- **Kullback–Leibler (KL) divergence**\n",
    "- **Sliced Wasserstein distance**\n",
    "\n",
    "This notebook evaluates how well wGMM–UAPCA preserves label-specific structures in low-dimensional representations.\n",
    "\n",
    "*Note:* Minor numerical differences may occur across systems due to implementation details of `scipy.stats.gaussian_kde` and stochastic sampling in the Sliced Wasserstein distance computation. These discrepancies may lead to slight variations between the results obtained here and those reported in the paper above, but they do not affect the qualitative conclusions of the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9965e7",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "Load the main `wgmm_uapca` library and packages needed and set random seed of NumPy for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08fff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wgmm_uapca as wgmm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import ot\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b6d09",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define utility functions for converting 2D density grids to samples, and for computing **KL divergence** and **sliced Wasserstein distance** between projected distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2f0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _density_to_samples(density: np.ndarray, n_samples: int = 1000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a 2D density grid into samples using weighted sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    density : np.ndarray\n",
    "        2D density array.\n",
    "    n_samples : int, default=1000\n",
    "        Number of samples to draw.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    samples : np.ndarray\n",
    "        Array of sampled points of shape (n_samples, 2).\n",
    "    \"\"\"\n",
    "    density = density / np.sum(density)\n",
    "\n",
    "    h, w = density.shape\n",
    "    X, Y = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "    coords = np.stack([X.ravel(), Y.ravel()], axis=1)\n",
    "\n",
    "    indices = np.random.choice(len(coords), size=n_samples, p=density.ravel())\n",
    "\n",
    "    return coords[indices]\n",
    "\n",
    "\n",
    "def compute_sliced_wasserstein_distance(density1: np.ndarray, density2: np.ndarray, n_samples: int = 5000, n_projections: int = 50) -> float:\n",
    "    \"\"\"\n",
    "    Compute the sliced Wasserstein distance between two 2D densities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    density1 : np.ndarray\n",
    "        First 2D density array.\n",
    "    density2 : np.ndarray\n",
    "        Second 2D density array.\n",
    "    n_samples : int, default=1000\n",
    "        Number of samples drawn from each density.\n",
    "    n_projections : int, default=50\n",
    "        Number of random 1D projections.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    swd : float\n",
    "        Scalar sliced Wasserstein distance.\n",
    "    \"\"\"\n",
    "    X_a = _density_to_samples(density1, n_samples)\n",
    "    X_b = _density_to_samples(density2, n_samples)\n",
    "\n",
    "    return ot.sliced.sliced_wasserstein_distance(X_a, X_b, n_projections=n_projections, seed=0)\n",
    "\n",
    "\n",
    "def compute_kl_divergence(ref: np.ndarray, comp: np.ndarray, grid: tuple[np.ndarray, np.ndarray]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the KL divergence D_KL(ref || comp) between two 2D densities on a grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ref : np.ndarray\n",
    "        Reference 2D density array.\n",
    "    comp : np.ndarray\n",
    "        Comparison 2D density array.\n",
    "    grid : tuple[np.ndarray, np.ndarray]\n",
    "        Meshgrid arrays (xx, yy) defining the grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kl : float\n",
    "        Scalar KL divergence value.\n",
    "    \"\"\"\n",
    "    xx, yy = grid\n",
    "    eps = 1e-10\n",
    "\n",
    "    p = ref / np.sum(ref)\n",
    "    q = comp / np.sum(comp)\n",
    "\n",
    "    mask = q > 0\n",
    "\n",
    "    dx = xx[0, 1] - xx[0, 0]\n",
    "    dy = yy[1, 0] - yy[0, 0]\n",
    "\n",
    "    return np.sum(p[mask] * (np.log(p[mask] + eps) - np.log(q[mask] + eps))) * dx * dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9736faf",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "In this step, we load multiple benchmark datasets provided by [Espadoto et al. (2021)](https://doi.org/10.1109/TVCG.2019.2944182) and prepare them for evaluation. For each dataset, we:\n",
    "\n",
    "1. **Fit Gaussian Mixture Models (GMMs)** for each label to model label-specific distributions.\n",
    "2. **Compute label weights** based on the number of samples per label.\n",
    "3. **Calculate 2D projections** using WGMM-UAPCA, UAPCA, and standard PCA.\n",
    "4. **Generate density grids** for each method to enable distribution comparison.\n",
    "5. **Visualize and save projections** along with density contours for qualitative assessment.\n",
    "6. **Compute quantitative measures** (KL divergence and sliced Wasserstein distance) for each label and method comparison.\n",
    "\n",
    "All computed measures are saved as a CSV file into `results/measures.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets or download them if not downloaded yet\n",
    "dataset_names = ['bank', 'cifar10', 'cnae9', 'coil20', 'epileptic', 'fashion_mnist', 'fmd', 'har', 'hatespeech', \n",
    "                 'hiva', 'imdb', 'secom', 'seismic', 'sentiment', 'sms', 'spambase', 'svhn']\n",
    "datasets = wgmm.load_datasets(dataset_names)\n",
    "\n",
    "# Get CSV file ready\n",
    "csv_file = \"./results/measures.csv\"\n",
    "os.makedirs(os.path.dirname(csv_file), exist_ok=True)\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    X, y = dataset\n",
    "\n",
    "    # Fit GMMs to each label for this dataset\n",
    "    gmms = wgmm.fit_gmms(dataset_name, dataset)\n",
    "\n",
    "    # Calculate projection matrix with equal weights\n",
    "    label_weights = y[\"Label\"].value_counts(normalize=True).to_dict()\n",
    "    weights = np.array([label_weights[label] for label in gmms.keys()])\n",
    "    P = wgmm.calculate_projmat(gmms, weights, n_dims=2)\n",
    "\n",
    "    # Grid for density estimation\n",
    "    xx, yy = wgmm.calculate_grid(gmms, P)\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    grid = (xx, yy)\n",
    "\n",
    "    projections = {\n",
    "        \"WGMM-UAPCA\": wgmm.wgmm_uapca(gmms, P),\n",
    "        \"UAPCA\": wgmm.uapca(gmms, P),\n",
    "        \"PCA\": wgmm.pca(dataset, P)\n",
    "    }\n",
    "\n",
    "    # Calculate densities for each projection method\n",
    "    densities = {method: wgmm.calculate_density(proj, grid) for method, proj in projections.items()}\n",
    "\n",
    "    # Project original data and plot each projection\n",
    "    X_proj = X.values @ P\n",
    "    wgmm.plot_and_save_projections(dataset_name, X_proj, y, densities, grid)\n",
    "\n",
    "    comparisons = [\n",
    "        (\"PCA\", \"WGMM-UAPCA\"),\n",
    "        (\"PCA\", \"UAPCA\")\n",
    "    ]\n",
    "\n",
    "    # Compute measures for each comparison\n",
    "    for ref_name, comp_name in comparisons:\n",
    "        kl_sum = 0\n",
    "        swd_sum = 0\n",
    "        for label in gmms.keys():\n",
    "            ref_density = densities[ref_name][label]\n",
    "            comp_density = densities[comp_name][label]\n",
    "\n",
    "            # KL Divergence\n",
    "            kl_sum += label_weights[label] * compute_kl_divergence(ref_density, comp_density, grid)\n",
    "\n",
    "            # Sliced Wasserstein Distance\n",
    "            swd_sum += label_weights[label] * compute_sliced_wasserstein_distance(ref_density, comp_density, n_samples=5000, n_projections=50)\n",
    "\n",
    "        results.append({\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"ref_approach\": ref_name,\n",
    "            \"comp_approach\": comp_name,\n",
    "            \"kl_divergence\": kl_sum,\n",
    "            \"wasserstein_distance\": swd_sum\n",
    "        })\n",
    "\n",
    "# Save results to CSV\n",
    "measures_df = pd.DataFrame(results)\n",
    "measures_df.to_csv(csv_file, index=False)\n",
    "print(f\"Evaluation Successful. Results have been saved to: {csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
